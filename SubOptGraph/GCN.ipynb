{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import random\n",
    "#import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing, GraphNorm\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "from torch_scatter import scatter\n",
    "import pandas as pd\n",
    "from torch_scatter import scatter_add\n",
    "import os.path as osp\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from torch_geometric.loader import DataLoader\n",
    "from Graph_ import Mol2Graph\n",
    "from cal_descriptors_ import cal_des\n",
    "import fit\n",
    "from typing import Union, Optional\n",
    "from torch_geometric.typing import (Adj, Size, OptTensor, PairTensor)  #\n",
    "#import torch\n",
    "from torch import Tensor\n",
    "#import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear, BatchNorm1d\n",
    "from torch_sparse import SparseTensor\n",
    "#from torch_geometric.nn.conv import MessagePassing\n",
    "#from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.inits import glorot  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_dataset\n",
    "train_data,test_data = load_dataset('data/emi','emi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/emi/data.txt'\n",
    "items = [i.strip().split('\\t') for i in open(path).readlines()] \n",
    "number = len(items)\n",
    "Y = np.array([float(i[-1]) for i in items])\n",
    "std = Y.std()\n",
    "mean = Y.mean()   \n",
    "print(mean,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    " \n",
    "class GraphConvolution(torch.nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.conv1 = GCNConv(input_size,output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    " \n",
    " \n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        '''\n",
    "        GCN\n",
    "        '''\n",
    "        x = self.relu(self.conv1(x, edge_index,edge_weight))\n",
    "        #x = self.MLP(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OledConv(torch.nn.Module):  #\n",
    "    def __init__(self, layer=5,hidden_size=128):  \n",
    "        super().__init__()  # \"Add\" aggregation (Step 5)\n",
    "        self.encoder = nn.Linear(46,hidden_size)\n",
    "        self.gcn = nn.ModuleList([GraphConvolution(hidden_size,hidden_size) for i in range(layer)])\n",
    "        self.norms = nn.ModuleList([nn.BatchNorm1d(hidden_size) for _ in range(layer)])\n",
    "                \n",
    "        self.encoder_sol = nn.Linear(46,hidden_size)\n",
    "        self.gcn_sol = nn.ModuleList([GraphConvolution(hidden_size,hidden_size) for i in range(layer)])\n",
    "        self.norms_sol = nn.ModuleList([nn.BatchNorm1d(hidden_size) for _ in range(layer)])\n",
    "        \n",
    "        self.gru = nn.ModuleList([nn.GRU(hidden_size,hidden_size) for _ in range(layer)])\n",
    "        self.gru_sol = nn.ModuleList([nn.GRU(hidden_size,hidden_size) for _ in range(layer)])\n",
    "        \n",
    "        self.MLP = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, hidden_size * 2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size *4)\n",
    "            )\n",
    "        self.MLP_sol = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, hidden_size *2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size *4)\n",
    "            )\n",
    "        self.MLP_emb = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * 8, hidden_size * 4),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(hidden_size * 4, hidden_size *2)\n",
    "            )\n",
    "        self.MLP_pre = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(hidden_size, 1)\n",
    "            )\n",
    "        \n",
    "        self.out_dim = hidden_size\n",
    "        \n",
    "    def forward(self, data,data_sol):   #\n",
    "        \n",
    "        #for chromophere  \n",
    "        x = self.encoder(data.x)\n",
    "        x_sol = self.encoder(data_sol.x)\n",
    "\n",
    "        h = x.unsqueeze(0)\n",
    "        h_ = x_sol.unsqueeze(0)\n",
    "        for i,(gcn,gcn_sol,norm,norm_sol,gru,gru_sol) in enumerate(zip(self.gcn,self.gcn_sol,self.norms,self.norms_sol,self.gru,self.gru_sol)):\n",
    "            x = gcn(x,data.edge_index,data.edge_weight)    \n",
    "            x,h = gru(x.unsqueeze(0),h)\n",
    "            x = norm(x.squeeze(0))\n",
    "            x_sol = gcn_sol(x_sol,data_sol.edge_index,data_sol.edge_weight)\n",
    "            x_sol,h_ = gru_sol(x_sol.unsqueeze(0),h_)\n",
    "            x_sol = norm_sol(x_sol.squeeze(0))\n",
    "            \n",
    "        x = scatter_add(x.reshape(-1,self.out_dim),dim=0,index=data.batch)\n",
    "        x_sol = scatter_add(x_sol.reshape(-1,self.out_dim),dim=0,index=data_sol.batch)\n",
    "\n",
    "        x = self.MLP(x)\n",
    "        x_sol = self.MLP_sol(x_sol)\n",
    "        \n",
    "        x = torch.cat([x,x_sol],dim=1)\n",
    "        x = self.MLP_emb(x)\n",
    "        \n",
    "        out = self.MLP_pre(x)\n",
    "        \n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=1,)\n",
    "valid_loader = DataLoader(test_data, batch_size=128, shuffle=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "import fit\n",
    "#import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model_name = 'OLED_GNN'\n",
    "data_loaders = {'train':train_loader, 'valid':valid_loader}#, 'test':test_loader}\n",
    "fit.training(OledConv, data_loaders, patience = 10,n_epoch=100, snapshot_path='./snapshot/{}//'.format('GCN_emi.12.27_new'), mean=mean, std=std,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
